import os
import requests
import csv
import time
from functools import partial
from multiprocessing import Pool

class Connections:
    def __init__(self, n: int, node:str, peer: str, time: int, tx: int, rx: int, code: int):
        self.iteration = n
        self.node = node
        self.peer = peer
        self.time = time
        self.tx = tx
        self.rx = rx
        self.code = code  # Added status_code


class NodeStatus:
    def __init__(self, node:str, success_rate: float):
        self.node = node
        self.success_rate = success_rate


def request(hostname, iters, wait):
    print("Running requests on %s" %hostname)
    results = []
    seconds = 0
    # sending get request and saving the response as response object
    for i in range(iters):
        print("Running iters on %s" %hostname)
        time.sleep(wait)
        try:
            r = requests.get("http://%s:9091/Info" %hostname, timeout=5)
            # extracting data in json format
            data = r.json()['node']['connections']
            for d in data:
                # Get the time information
                second = (time.time() - (d['peerConnectionTime']/1000))
                # Added status code to connection info
                nodeinfo = Connections(i, hostname, d['peerName'], second, d['tx'], d['rx'], r.status_code)
                results.append(nodeinfo)
        except requests.exceptions.RequestException as e:
            print(e)
    return results


def check():
    # get nodes
    nodes = os.environ.get('NODES').split(";")
    p = partial(request, iters=4, wait=1)

    with Pool(len(nodes)) as pool:
        print("Running multithreading")
        node_data = pool.map(p, nodes, 1)

    # with open('data.csv', 'w',) as csvfile:
    #     print("Running csv")
    #     writer = csv.writer(csvfile)
    #     writer.writerow(['iteration', 'nodeName','peerName', 'time[s]', 'tx', 'rx', 'status_code'])
    #     for nd in node_data:
    #         for r in nd:
    #             writer.writerow([r.iteration, r.node, r.peer, r.time, r.tx, r.rx, r.code])

    node_statuses = []  # Calculating nodes' statuses
    for node in node_data:
        if len(node) > 0:
            all_iterations = len(node)  # All requests count to the node
            successful_count = len([n for n in node if n.code == 200])  # Working requests count
            status = NodeStatus(node[0].node, successful_count / all_iterations * 100)
            node_statuses.append(status)

    with open('node_statuses.csv', 'w',) as csvfile: # Writing statuses to file
        print("Writing node statuses")
        writer = csv.writer(csvfile)
        writer.writerow(['nodeName', 'successRate', 'time'])
        for ns in node_statuses:
            writer.writerow([ns.node, ns.success_rate, time.time()])


if __name__ == "__main__":
    i = 0
    while i < 3:  # Runs 3 times
        try:
            check()
            time.sleep(5 * 60)
            i += 1
        except KeyboardInterrupt:
            print('exiting...')
            break
